{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_tomogram_dataset.utils import calculate_edge_mean_2d\n",
    "from torch_tomogram_dataset.transforms import augmentation_transform_2d\n",
    "\n",
    "class Qata(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, augmentation=False):\n",
    "        super().__init__()\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.augmentation = augmentation\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        \n",
    "        states = ['good', 'bad']\n",
    "        for label, state in enumerate(states):\n",
    "            path = os.path.join(self.root_dir, state)\n",
    "            for file in os.listdir(path):\n",
    "                data = Image.open(os.path.join(path, file)).convert('L')\n",
    "                data = torch.from_numpy(np.array(data))\n",
    "                \n",
    "                self.samples.append(data)\n",
    "                self.labels.append(label)\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_tensor = self.samples[idx]\n",
    "        image_tensor = image_tensor.float().unsqueeze(0).repeat(3, 1, 1)\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image_tensor = self.transform(image_tensor)\n",
    "        \n",
    "        # Rotation with edge mean filling\n",
    "        if self.augmentation:\n",
    "            edge_mean = calculate_edge_mean_2d(image_tensor)\n",
    "            image_tensor = augmentation_transform_2d(image_tensor)\n",
    "            image_tensor[image_tensor==0] = edge_mean\n",
    "\n",
    "        return image_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_tomogram_dataset import AugmentedDatasetWrapper\n",
    "from torchvision import models\n",
    "\n",
    "train_dir = r\"C:\\rkka_Projects\\cell_death_v1\\Data\\qpi_output\\quality\\train\"\n",
    "val_dir = r\"C:\\rkka_Projects\\cell_death_v1\\Data\\qpi_output\\quality\\val\"\n",
    "\n",
    "transform = models.ResNet50_Weights.IMAGENET1K_V2.transforms()\n",
    "\n",
    "train_dataset = Qata(root_dir=train_dir, transform=transform, augmentation=True)\n",
    "augmented_train_dataset = AugmentedDatasetWrapper(dataset=train_dataset, num_repeats=3)\n",
    "val_dataset = Qata(root_dir=val_dir, transform=transform, augmentation=False)\n",
    "\n",
    "train_loader = DataLoader(augmented_train_dataset, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 23,512,130\n",
      "Trainable Parameters: 4,466,690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\envs\\cell\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\miniconda3\\envs\\cell\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(num_features, 2)\n",
    ")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if 'layer4.1' in name or 'fc' in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "    \n",
    "# Count total and trainable parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total Parameters: {total_params:,}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:02<00:44,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "train loss : 0.023813 || train accuracy : 0.5084\n",
      "val loss : 0.020813 || val accuracy : 0.8922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:04<00:40,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "train loss : 0.021206 || train accuracy : 0.5868\n",
      "val loss : 0.018020 || val accuracy : 0.8922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:06<00:37,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2\n",
      "train loss : 0.021485 || train accuracy : 0.5840\n",
      "val loss : 0.016906 || val accuracy : 0.9020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [00:08<00:35,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3\n",
      "train loss : 0.020308 || train accuracy : 0.6443\n",
      "val loss : 0.015475 || val accuracy : 0.9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:11<00:33,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4\n",
      "train loss : 0.020010 || train accuracy : 0.6583\n",
      "val loss : 0.013955 || val accuracy : 0.9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:13<00:31,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5\n",
      "train loss : 0.019354 || train accuracy : 0.6891\n",
      "val loss : 0.014619 || val accuracy : 0.9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [00:15<00:28,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6\n",
      "train loss : 0.017832 || train accuracy : 0.7787\n",
      "val loss : 0.014261 || val accuracy : 0.9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [00:17<00:25,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7\n",
      "train loss : 0.017122 || train accuracy : 0.7899\n",
      "val loss : 0.013516 || val accuracy : 0.9314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:19<00:23,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8\n",
      "train loss : 0.015693 || train accuracy : 0.8557\n",
      "val loss : 0.012458 || val accuracy : 0.9412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [00:22<00:21,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9\n",
      "train loss : 0.014403 || train accuracy : 0.8936\n",
      "val loss : 0.012457 || val accuracy : 0.9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:24<00:19,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10\n",
      "train loss : 0.012981 || train accuracy : 0.9356\n",
      "val loss : 0.012440 || val accuracy : 0.9216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [00:26<00:16,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 11\n",
      "train loss : 0.011482 || train accuracy : 0.9524\n",
      "val loss : 0.012202 || val accuracy : 0.9412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [00:28<00:14,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 12\n",
      "train loss : 0.010357 || train accuracy : 0.9720\n",
      "val loss : 0.012073 || val accuracy : 0.9314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [00:30<00:12,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 13\n",
      "train loss : 0.009877 || train accuracy : 0.9692\n",
      "val loss : 0.012439 || val accuracy : 0.9314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [00:32<00:10,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 14\n",
      "train loss : 0.008875 || train accuracy : 0.9832\n",
      "val loss : 0.011889 || val accuracy : 0.9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [00:34<00:08,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 15\n",
      "train loss : 0.008351 || train accuracy : 0.9860\n",
      "val loss : 0.011125 || val accuracy : 0.9412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [00:36<00:06,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 16\n",
      "train loss : 0.007917 || train accuracy : 0.9846\n",
      "val loss : 0.011570 || val accuracy : 0.9216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [00:38<00:04,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 17\n",
      "train loss : 0.007261 || train accuracy : 0.9902\n",
      "val loss : 0.011400 || val accuracy : 0.9510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [00:40<00:02,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 18\n",
      "train loss : 0.006632 || train accuracy : 0.9972\n",
      "val loss : 0.010959 || val accuracy : 0.9216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:43<00:00,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 19\n",
      "train loss : 0.006403 || train accuracy : 0.9902\n",
      "val loss : 0.011226 || val accuracy : 0.9510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Train\n",
    "num_epoch = 20\n",
    "\n",
    "for epoch in tqdm(range(num_epoch)):\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss, train_correct, train_total = 0, 0, 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        \n",
    "        # Calculate\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_correct += (preds==labels).sum().item()\n",
    "        train_total += len(labels)\n",
    "        \n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += (preds==labels).sum().item()\n",
    "            val_total += len(labels)\n",
    "        \n",
    "    print(f\"Epoch : {epoch}\")\n",
    "    print(f\"train loss : {train_loss/train_total:.6f} || train accuracy : {train_correct/train_total:.4f}\")\n",
    "    print(f\"val loss : {val_loss/val_total:.6f} || val accuracy : {val_correct/val_total:.4f}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), f\"epoch_{epoch}_valacc_{val_correct/val_total:.4f}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'sparsity_check.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
